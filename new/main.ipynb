{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d636e0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from icosahedron_gen import IcosahedralGrid\n",
    "from volumetric_surface_parameterization import VolumetricSphericalParameterization\n",
    "from crsm import CRSM\n",
    "from gat_stack import GATStack\n",
    "from ico_blocks import IcoUNet\n",
    "from s2c_head import S2CHead\n",
    "from integration import ScalingAndSquaring\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d11cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices: torch.Size([40962, 3])\n",
      "Edges: torch.Size([2, 245760])\n"
     ]
    }
   ],
   "source": [
    "grid = IcosahedralGrid(subdivisions=6)\n",
    "print(\"Vertices:\", grid.vertices.shape)\n",
    "print(\"Edges:\", grid.edge_index.shape)\n",
    "# grid.visualize(save_path=\"ico.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594f4c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42])\n",
      "torch.Size([162])\n",
      "torch.Size([642])\n",
      "torch.Size([2562])\n",
      "torch.Size([10242])\n",
      "torch.Size([40962])\n"
     ]
    }
   ],
   "source": [
    "for each in grid.up_maps:\n",
    "    print(each.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9113ec2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed_volume shape: torch.Size([256, 256, 256])\n",
      "moving_volume shape: torch.Size([256, 256, 256])\n",
      "\n",
      "Processing moving volume...\n",
      "Moving features shape (data_moving.x): torch.Size([40962, 11])\n",
      "Processing fixed volume...\n",
      "Fixed features shape (data_fixed.x): torch.Size([40962, 11])\n",
      "\n",
      "--- Final Combined Data for Network ---\n",
      "Shape of combined features (data.x): torch.Size([40962, 22])\n",
      "Shape of edge index (data.edge_index): torch.Size([2, 245760])\n"
     ]
    }
   ],
   "source": [
    "template_npy = np.load(\"/shared/scratch/0/home/v_nishchay_nilabh/oasis_data/scans/OASIS_OAS1_0406_MR1/seg4_onehot.npy\")\n",
    "template = torch.from_numpy(template_npy)\n",
    "labels_fixed = torch.argmax(template, dim=0)\n",
    "fixed_volume = (labels_fixed > 0).long() \n",
    "print(\"fixed_volume shape:\", fixed_volume.shape)\n",
    "\n",
    "sample_npy = np.load(\"/shared/scratch/0/home/v_nishchay_nilabh/oasis_data/scans/OASIS_OAS1_0021_MR1/seg4_onehot.npy\")\n",
    "sample = torch.from_numpy(sample_npy)\n",
    "labels_moving = torch.argmax(sample, dim=0)\n",
    "moving_volume = (labels_moving > 0).long()\n",
    "print(\"moving_volume shape:\", moving_volume.shape)\n",
    "\n",
    "vsp = VolumetricSphericalParameterization()\n",
    "\n",
    "print(\"\\nProcessing moving volume...\")\n",
    "data_moving = vsp(moving_volume, grid.vertices, grid.edge_index)\n",
    "print(f\"Moving features shape (data_moving.x): {data_moving.x.shape}\")\n",
    "\n",
    "print(\"Processing fixed volume...\")\n",
    "data_fixed = vsp(fixed_volume, grid.vertices, grid.edge_index)\n",
    "print(f\"Fixed features shape (data_fixed.x): {data_fixed.x.shape}\")\n",
    "\n",
    "combined_features = torch.cat([data_moving.x, data_fixed.x], dim=1)\n",
    "data = Data(x=combined_features, edge_index=data_moving.edge_index)\n",
    "\n",
    "print(\"\\n--- Final Combined Data for Network ---\")\n",
    "print(f\"Shape of combined features (data.x): {data.x.shape}\")\n",
    "print(f\"Shape of edge index (data.edge_index): {data.edge_index.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8fe4c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40962, 22])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67dd573d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([40962, 22])\n",
      "Output shape: torch.Size([40962, 8])\n"
     ]
    }
   ],
   "source": [
    "crsm = CRSM(radial_channel_indices=range(22), conical_depth_indices=[0, 5, 10, 11, 16, 21], aggregation='mean', mlp_hidden=(32,16,), mlp_out_dim=8).cuda()\n",
    "\n",
    "data_crsm = crsm(data)\n",
    "print(\"Input shape:\", data.x.shape)\n",
    "print(\"Output shape:\", data_crsm.x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e90edc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATStack(\n",
      "  (layers): ModuleList(\n",
      "    (0): GATBlock(\n",
      "      (gat): GATConv(8, 16, heads=4)\n",
      "      (residual): Linear(in_features=8, out_features=64, bias=True)\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (act): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (1): GATBlock(\n",
      "      (gat): GATConv(64, 16, heads=4)\n",
      "      (residual): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (act): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (2): GATBlock(\n",
      "      (gat): GATConv(64, 16, heads=1)\n",
      "      (residual): Linear(in_features=64, out_features=16, bias=True)\n",
      "      (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      (act): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "After GAT stack - shape: torch.Size([40962, 16])\n"
     ]
    }
   ],
   "source": [
    "gat = GATStack(in_channels=data_crsm.x.size(1), hidden_channels=16, out_channels=16, num_layers=3, heads=4, dropout=0.1).cuda()\n",
    "print(gat)\n",
    "x_gat = gat(data_crsm.x, data_crsm.edge_index)\n",
    "data_gat = data_crsm\n",
    "data_gat.x = x_gat\n",
    "print(\"After GAT stack - shape:\", data_gat.x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d498b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_pool_tensor(pool_dict, device=\"cuda\"):\n",
    "    Nc = max(pool_dict.keys()) + 1\n",
    "    k = max(len(v) for v in pool_dict.values())\n",
    "    pool_tensor = torch.full((Nc, k), -1, dtype=torch.long, device=device)\n",
    "    for c, fine_list in pool_dict.items():\n",
    "        pool_tensor[c, :len(fine_list)] = torch.tensor(fine_list, dtype=torch.long, device=device)\n",
    "    return pool_tensor\n",
    "\n",
    "def dict_to_up_tensor(pool_dict, device=\"cuda\"):\n",
    "    # pool_dict: coarse->list(fine)\n",
    "    Nf = max(max(v) for v in pool_dict.values()) + 1\n",
    "    up_tensor = torch.full((Nf,), -1, dtype=torch.long, device=device)\n",
    "    for c, fine_list in pool_dict.items():\n",
    "        for f in fine_list:\n",
    "            up_tensor[f] = c\n",
    "    return up_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71b55a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to model: torch.Size([1, 16, 40962])\n",
      "up_map.shape torch.Size([42]) dtype torch.int64\n",
      "min, max 0 11\n",
      "coarse_feats.shape torch.Size([1, 1024, 12])\n",
      "up_map.shape torch.Size([162]) dtype torch.int64\n",
      "min, max 0 41\n",
      "coarse_feats.shape torch.Size([1, 512, 42])\n",
      "up_map.shape torch.Size([642]) dtype torch.int64\n",
      "min, max 0 161\n",
      "coarse_feats.shape torch.Size([1, 512, 162])\n",
      "up_map.shape torch.Size([2562]) dtype torch.int64\n",
      "min, max 0 641\n",
      "coarse_feats.shape torch.Size([1, 256, 642])\n",
      "up_map.shape torch.Size([10242]) dtype torch.int64\n",
      "min, max 0 2561\n",
      "coarse_feats.shape torch.Size([1, 128, 2562])\n",
      "up_map.shape torch.Size([40962]) dtype torch.int64\n",
      "min, max 0 10241\n",
      "coarse_feats.shape torch.Size([1, 64, 10242])\n",
      "Output shape: torch.Size([1, 40962, 16])\n"
     ]
    }
   ],
   "source": [
    "# 1. Handle each map list according to its data type and required order.\n",
    "\n",
    "# grid.pool_maps is a list of dicts. Reverse it for the downsampling path.\n",
    "pool_maps_full = [dict_to_pool_tensor(m) for m in reversed(grid.pool_maps)]\n",
    "\n",
    "# grid.up_maps is already a list of tensors in the correct (coarse-to-fine) order.\n",
    "up_maps_full = [m.to(device) for m in grid.up_maps]\n",
    "\n",
    "# 2. Define the channel architecture for all 6 levels\n",
    "channels_full = [32, 64, 128, 256, 512, 512] \n",
    "\n",
    "# 3. Instantiate the IcoUNet with the complete configuration\n",
    "model = IcoUNet(\n",
    "    in_ch=16,\n",
    "    channels=channels_full,\n",
    "    pool_maps=pool_maps_full,\n",
    "    up_maps=up_maps_full\n",
    ").to(device)\n",
    "\n",
    "# 4. Prepare your input data\n",
    "x = data_gat.x\n",
    "x = x.unsqueeze(0).permute(0, 2, 1).to(device) # -> [1, 16, 40962]\n",
    "\n",
    "print(f\"Input shape to model: {x.shape}\")\n",
    "\n",
    "# Forward pass\n",
    "with torch.backends.cudnn.flags(enabled=False):\n",
    "    out = model(x).permute(0, 2, 1)\n",
    "\n",
    "print(f\"Output shape: {out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30dc0a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 16, 16, 3])\n"
     ]
    }
   ],
   "source": [
    "head = S2CHead(in_channels=16).cuda()\n",
    "\n",
    "out_size = (16, 16, 16) # D, H, W\n",
    "u = head(out, grid.vertices, out_size)\n",
    "\n",
    "print(\"Output shape:\", u.shape)\n",
    "# Expected: (16, 16, 16, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdbaa905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final full-resolution deformation field shape: torch.Size([256, 256, 256, 3])\n"
     ]
    }
   ],
   "source": [
    "u_permuted = u.permute(3, 0, 1, 2).unsqueeze(0) # Shape: [1, 3, 16, 16, 16]\n",
    "\n",
    "# Define the target size\n",
    "full_size = (256, 256, 256)\n",
    "\n",
    "# Upsample using trilinear interpolation\n",
    "u_full_res = torch.nn.functional.interpolate(u_permuted, size=full_size, mode='trilinear', align_corners=False)\n",
    "\n",
    "# Remove the batch dimension and permute back\n",
    "u_full_res = u_full_res.squeeze(0).permute(1, 2, 3, 0) # Shape: [256, 256, 256, 3]\n",
    "\n",
    "print(f\"Final full-resolution deformation field shape: {u_full_res.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d588b318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returned map and displacement shapes: torch.Size([256, 256, 256, 3]) torch.Size([256, 256, 256, 3])\n"
     ]
    }
   ],
   "source": [
    "integrator = ScalingAndSquaring(max_scale=0.5).to(device)\n",
    "\n",
    "# also obtain displacement field\n",
    "phi_map, disp = integrator(u_full_res, return_displacement=True)\n",
    "print('returned map and displacement shapes:', phi_map.shape, disp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcddc167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displacement field shape: torch.Size([1, 3, 256, 256, 256])\n",
      "Moving scan shape for STN: torch.Size([1, 1, 256, 256, 256])\n",
      "\n",
      "Successfully warped scan!\n",
      "Final warped scan shape: torch.Size([1, 1, 256, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "from spatial_transformer import SpatialTransformer\n",
    "\n",
    "stn = SpatialTransformer(size=(256, 256, 256), device=device)\n",
    "\n",
    "disp_batch = disp.permute(3, 0, 1, 2).unsqueeze(0)\n",
    "moving_volume_batch = moving_volume.float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "print(f\"Displacement field shape: {disp_batch.shape}\")\n",
    "print(f\"Moving scan shape for STN: {moving_volume_batch.shape}\")\n",
    "warped_scan = stn(moving=moving_volume_batch, flow=disp_batch)\n",
    "\n",
    "print(f\"\\nSuccessfully warped scan!\")\n",
    "print(f\"Final warped scan shape: {warped_scan.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "039cfe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6205, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from losses import composite_loss\n",
    "\n",
    "print(composite_loss(fixed_volume.float().cuda(), warped_scan[0][0].cuda(), disp_batch.cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217456df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
